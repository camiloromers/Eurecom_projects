{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018 Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge: What is the future selling price of a home?\n",
    "\n",
    "A home is often the largest and most expensive purchase a person makes in his or her lifetime. Ensuring homeowners have a trusted way to monitor this asset is incredibly important.\n",
    "\n",
    "In this competition, students are required to develop a full-fledged approach to make predictions about the future sale prices of homes. A full-fledged approach constist, at least, in the following steps:\n",
    "\n",
    "* Descriptive statistics about the data\n",
    "* Data cleaning and pre-processing\n",
    "* Defining a modeling approach to the problem\n",
    "* Build such a statistical model\n",
    "* Validate the outcome of the model\n",
    "\n",
    "Now, should you ask a home buyer to describe their dream house, they probably wouldn't begin with describing features such as the height of the basement ceiling or the proximity to a railroad. As you will see, the dataset we use in this competition proves that many more features influence price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in a small city in the US, this competition challenges you to predict the final price of each home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The dataset\n",
    "\n",
    "## File descriptions\n",
    "\n",
    "* train.csv - the training dataset\n",
    "* test.csv - the test dataset\n",
    "* data_description.txt - full description of each column\n",
    "\n",
    "## Data fields\n",
    "Here's a brief version of what you'll find in the data description file.\n",
    "\n",
    "* SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "* MSSubClass: The building class\n",
    "* MSZoning: The general zoning classification\n",
    "* LotFrontage: Linear feet of street connected to property\n",
    "* LotArea: Lot size in square feet\n",
    "* Street: Type of road access\n",
    "* Alley: Type of alley access\n",
    "* LotShape: General shape of property\n",
    "* LandContour: Flatness of the property\n",
    "* Utilities: Type of utilities available\n",
    "* LotConfig: Lot configuration\n",
    "* LandSlope: Slope of property\n",
    "* Neighborhood: Physical locations within Ames city limits\n",
    "* Condition1: Proximity to main road or railroad\n",
    "* Condition2: Proximity to main road or railroad (if a second is present)\n",
    "* BldgType: Type of dwelling\n",
    "* HouseStyle: Style of dwelling\n",
    "* OverallQual: Overall material and finish quality\n",
    "* OverallCond: Overall condition rating\n",
    "* YearBuilt: Original construction date\n",
    "* YearRemodAdd: Remodel date\n",
    "* RoofStyle: Type of roof\n",
    "* RoofMatl: Roof material\n",
    "* Exterior1st: Exterior covering on house\n",
    "* Exterior2nd: Exterior covering on house (if more than one material)\n",
    "* MasVnrType: Masonry veneer type\n",
    "* MasVnrArea: Masonry veneer area in square feet\n",
    "* ExterQual: Exterior material quality\n",
    "* ExterCond: Present condition of the material on the exterior\n",
    "* Foundation: Type of foundation\n",
    "* BsmtQual: Height of the basement\n",
    "* BsmtCond: General condition of the basement\n",
    "* BsmtExposure: Walkout or garden level basement walls\n",
    "* BsmtFinType1: Quality of basement finished area\n",
    "* BsmtFinSF1: Type 1 finished square feet\n",
    "* BsmtFinType2: Quality of second finished area (if present)\n",
    "* BsmtFinSF2: Type 2 finished square feet\n",
    "* BsmtUnfSF: Unfinished square feet of basement area\n",
    "* TotalBsmtSF: Total square feet of basement area\n",
    "* Heating: Type of heating\n",
    "* HeatingQC: Heating quality and condition\n",
    "* CentralAir: Central air conditioning\n",
    "* Electrical: Electrical system\n",
    "* 1stFlrSF: First Floor square feet\n",
    "* 2ndFlrSF: Second floor square feet\n",
    "* LowQualFinSF: Low quality finished square feet (all floors)\n",
    "* GrLivArea: Above grade (ground) living area square feet\n",
    "* BsmtFullBath: Basement full bathrooms\n",
    "* BsmtHalfBath: Basement half bathrooms\n",
    "* FullBath: Full bathrooms above grade\n",
    "* HalfBath: Half baths above grade\n",
    "* Bedroom: Number of bedrooms above basement level\n",
    "* Kitchen: Number of kitchens\n",
    "* KitchenQual: Kitchen quality\n",
    "* TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "* Functional: Home functionality rating\n",
    "* Fireplaces: Number of fireplaces\n",
    "* FireplaceQu: Fireplace quality\n",
    "* GarageType: Garage location\n",
    "* GarageYrBlt: Year garage was built\n",
    "* GarageFinish: Interior finish of the garage\n",
    "* GarageCars: Size of garage in car capacity\n",
    "* GarageArea: Size of garage in square feet\n",
    "* GarageQual: Garage quality\n",
    "* GarageCond: Garage condition\n",
    "* PavedDrive: Paved driveway\n",
    "* WoodDeckSF: Wood deck area in square feet\n",
    "* OpenPorchSF: Open porch area in square feet\n",
    "* EnclosedPorch: Enclosed porch area in square feet\n",
    "* 3SsnPorch: Three season porch area in square feet\n",
    "* ScreenPorch: Screen porch area in square feet\n",
    "* PoolArea: Pool area in square feet\n",
    "* PoolQC: Pool quality\n",
    "* Fence: Fence quality\n",
    "* MiscFeature: Miscellaneous feature not covered in other categories\n",
    "* MiscVal: Value (in dollars) of miscellaneous feature\n",
    "* MoSold: Month Sold\n",
    "* YrSold: Year Sold\n",
    "* SaleType: Type of sale\n",
    "* SaleCondition: Condition of sale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal of the challenge\n",
    "\n",
    "It is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable.\n",
    "\n",
    "## Metric\n",
    "Notebooks are evaluated on Root-Mean-Squared-Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price. (Taking logs means that errors in predicting expensive houses and cheap houses will affect the result equally.)\n",
    "\n",
    "## Submission File Format\n",
    "The file should contain a header and have the following format:\n",
    "\n",
    "```\n",
    "Id,SalePrice\n",
    "1461,169000.1\n",
    "1462,187724.1233\n",
    "1463,175221\n",
    "etc.\n",
    "```\n",
    "\n",
    "You will find an example submission file within the data directory in the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grading the notebook\n",
    "\n",
    "This challenge is going to be graded as a regular notebook for the AML labs. As a consequence, students should submit:\n",
    "\n",
    "* the html version of the notebook, using the Data Science Labs submission website, as usual [**Assignement: Challenge Notebook**]\n",
    "* the submission file (in csv format), that we will use to rank students according to the metric defined above, again through the Data Science Labs submission website [**Assignement: Challenge Predictions**]\n",
    "\n",
    "In summary, you will have to submit 2 files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python3.5/dist-packages (10.0.1)\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.5/dist-packages (0.71)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.5/dist-packages (from xgboost) (1.0.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from xgboost) (1.14.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.5/dist-packages (0.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install xgboost\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import xgboost as xgb\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn import linear_model\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from xgboost.sklearn import XGBClassifier\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "plt.style.use('seaborn-dark-palette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'Data/'\n",
    "filename_train = 'train.csv'\n",
    "filename_test = 'test.csv'\n",
    "\n",
    "# Load training datset\n",
    "train = pd.read_csv(filepath + filename_train)\n",
    "train.head()\n",
    "\n",
    "# Load test dataset\n",
    "test = pd.read_csv(filepath + filename_test)\n",
    "\n",
    "# Merge dataset\n",
    "dataset = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's fix the Id column as index for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_index('Id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many feature are there?\n",
    "The following queries will describe some initial characteristics in the dataset how many training example how many predictors, target value there are and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns for train dataset\n",
    "numericCol_train = train.select_dtypes(include=[np.number]).columns\n",
    "categoCol_train = train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Columns for test dataset\n",
    "numericCol_test = test.select_dtypes(include=[np.number]).columns\n",
    "categoCol_test = test.select_dtypes(exclude=[np.number]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1200 taining and 260 test records which sale price is unknown.\n",
      "\n",
      "In the TRAIN dataset there are 79 features which target is called SalePrice\n",
      "The features in train set are split into\n",
      " - 37 numerical predicators \n",
      " - 43 categorical\n",
      "\n",
      "In the TEST dataset there are 78 features\n",
      "The features in test set are split into\n",
      " - 36 numerical predicators \n",
      " - 43 categorical\n"
     ]
    }
   ],
   "source": [
    "print ('There are {} taining and {} test records which sale price is unknown.'.format(len(train), len(test)))\n",
    "print ()\n",
    "\n",
    "print ('In the TRAIN dataset there are {} features which target is called {}' \\\n",
    "       .format(len(train.columns)-1, train.iloc[:,-1].name))\n",
    "print ('The features in train set are split into\\n - {} numerical predicators \\n - {} categorical'\\\n",
    "       .format(len(numericCol_train), len(categoCol_train)))\n",
    "\n",
    "print ()\n",
    "print ('In the TEST dataset there are {} features' \\\n",
    "       .format(len(test.columns)-1))\n",
    "print ('The features in test set are split into\\n - {} numerical predicators \\n - {} categorical'\\\n",
    "       .format(len(numericCol_test), len(categoCol_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of courser there exist -1 numerical feature because the target column SalePrice is unknown in test set. Let's continue  describing and go deeper into each datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LotFrontage      210\n",
       "Alley           1125\n",
       "MasVnrType         6\n",
       "MasVnrArea         6\n",
       "BsmtQual          32\n",
       "BsmtCond          32\n",
       "BsmtExposure      33\n",
       "BsmtFinType1      32\n",
       "BsmtFinType2      33\n",
       "FireplaceQu      564\n",
       "GarageType        67\n",
       "GarageYrBlt       67\n",
       "GarageFinish      67\n",
       "GarageQual        67\n",
       "GarageCond        67\n",
       "PoolQC          1196\n",
       "Fence            973\n",
       "MiscFeature     1153\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How mnay null values are in train set\n",
    "null_val = train.isnull().sum()\n",
    "null_val[null_val>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1200.000000\n",
       "mean     181414.628333\n",
       "std       81070.908544\n",
       "min       34900.000000\n",
       "25%      129900.000000\n",
       "50%      163700.000000\n",
       "75%      214000.000000\n",
       "max      755000.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb4243dd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "minVal = train['SalePrice'].min()\n",
    "maxVal = train['SalePrice'].max()\n",
    "\n",
    "# Non parametric density (gaussian kernel approximation)\n",
    "nparam_density = stats.kde.gaussian_kde(train['SalePrice'].values.ravel())\n",
    "x = np.linspace(minVal * 0.5, maxVal * 1.5, 300)\n",
    "nparam_density = nparam_density(x)\n",
    "\n",
    "\n",
    "# Sales Price Histogram and gaussian kernel approx\n",
    "fig = plt.subplots(figsize=(10, 6))\n",
    "plt.hist(train['SalePrice'].values, bins=30, normed=True, color = 'darkblue', alpha = 0.7)\n",
    "plt.plot(x, nparam_density, 'r-', lw=2, label='non-parametric density (smoothed by Gaussian kernel)')\n",
    "plt.title('Sales Price estimated distribution', fontsize = 18)\n",
    "plt.xlabel('Price in USD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean value is 181414.628\n",
      "The median value is 163700.000\n"
     ]
    }
   ],
   "source": [
    "print ('The mean value is {:.3f}'.format(train['SalePrice'].mean()))\n",
    "print ('The median value is {:.3f}'.format(train['SalePrice'].median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few charactistics:\n",
    "- Unimodal (one peak)\n",
    "- Right skew sample\n",
    "\n",
    "You can get a general impression of skewness by drawing a histogram but you cannot generalize about population *(remember our goal is to infer a house price in a Population)*. Before that, we need to compute if the sales price population data also tend to follow a skew distribution (for more details follow this __[link](https://brownmath.com/stat/shape.htm)__).\n",
    "\n",
    "\n",
    "**Inferring**\n",
    "\n",
    "\n",
    "The dataset is one sample drawn from a population. Sometimes the sample may be skewed but the population may not (could be symmetric). \n",
    "In order to try to answer this question Test Statistics come to my mind. \n",
    "\n",
    "Test Statistics are very useful to infer from a sample a variable which is representative in a population (mean, standard deviation, etc). At the end there will exist some grade of uncertainty in the population variable of interest and that's why the conclusion is based in terms of probability such as it is very likely that the the population is skewed or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stats_skewness(x):\n",
    "    '''Inferring Skewness at Population\n",
    "    n = number of samples\n",
    "    g1 = Measure of skewness \n",
    "    SES = stardard error of skewness\n",
    "    Z = Test statistics\n",
    "    '''\n",
    "    # numbers of samples\n",
    "    n = len(x)\n",
    "    # Third moment of the train\n",
    "    m3 = sum((x - x.mean())**3)/n\n",
    "    # Variance\n",
    "    m2 = sum((x - x.mean())**2)/n\n",
    "    # skewness\n",
    "    g1 = m3 / m2**(3/2)\n",
    "    # sample skewness (different from population skweness)\n",
    "    sampleSkew = math.sqrt(n * (n-1)) * g1 / (n-2)\n",
    "    # Test statistics\n",
    "    SES = math.sqrt(6*n*(n-1)/((n-2)*(n+1)*(n+3)))\n",
    "    Z = sampleSkew / SES\n",
    "    \n",
    "    return Z, sampleSkew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The skewness is: 1.9672\n",
      "The test statistics at 5% sign level of confidence is 27.855\n"
     ]
    }
   ],
   "source": [
    "testStat, skew = test_stats_skewness(train['SalePrice'])\n",
    "print ('The skewness is: {:.4f}'.format(skew))\n",
    "print ('The test statistics at 5% sign level of confidence is {:.3f}'.format(testStat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "- A Positive value greater than 1 means the distribution is highly skewed to the right but we are not sure if population is also skew.\n",
    "- The test statistics indicates the population is very likely to be skewed positively (greater than 2).\n",
    "- In simple terms, few people can afford luxury and expensive houses and a large amount or citizens can buy homes which prices oscilate around 163700 USD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation\n",
    "Spearman correlation not to conclude something about some features but more to have a good understanding about the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catch numerical columns\n",
    "numericalData = train._get_numeric_data()\n",
    "\n",
    "# Spearman correlation\n",
    "Corr = numericalData.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdbabff90f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Draw a heatmap with spearman correlation\n",
    "f = plt.subplots(figsize=(20, 13))\n",
    "sns.heatmap(Corr[::-1], annot=True, annot_kws={\"size\": 7}, linewidths=.003, cmap='mako')\n",
    "# sns.clustermap(Corr, cmap='mako', metric=\"correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information how to scale variables in python __[link](http://benalexkeen.com/feature-scaling-with-scikit-learn/)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numericalData = numericalData.fillna(-1)\n",
    "\n",
    "# # Binning target column\n",
    "# bins = [1, 50000, 250000, 400000,10000000]\n",
    "# labels = [1,2,3,4]\n",
    "# numericalData['binPrice'] = pd.cut(numericalData.SalePrice, bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_DF = numericalData.loc[:,('LotArea','1stFlrSF', 'GrLivArea', '2ndFlrSF', \\\n",
    "#                                   'TotRmsAbvGrd', 'binPirce')]\n",
    "\n",
    "# # Plot parallel coordinates\n",
    "# plt.figure(figsize=(20, 10))\n",
    "# parallel_coordinates(plot_DF, class_column='binPrice', cols=plot_DF.columns[:-1], colormap=plt.get_cmap('Set2'))\n",
    "# plt.yscale('symlog')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- House floor area = second floor are -> regular ones\n",
    "- Not all houses have second floor.\n",
    "- Ground living area is related to number of total rooms.\n",
    "- Second floor is linked price of house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ratio of price per total lote ft^2\n",
    "# pricesq = target / train['LotArea']\n",
    "\n",
    "# # Median and std (Price / ft^2) per neighborhood\n",
    "# priceNeighbor = pd.concat([train['Neighborhood'], pricesq], keys=['Neighborhood', 'medianPricesq'], axis=1)\\\n",
    "#                     .groupby(['Neighborhood'])\\\n",
    "#                     .agg(['median'])\\\n",
    "#                     .reset_index()\n",
    "\n",
    "# # Delete one level index\n",
    "# priceNeighbor.columns = priceNeighbor.columns.droplevel(1)\n",
    "# # SortDF\n",
    "# sortDF = priceNeighbor.sort_values(by='medianPricesq')\n",
    "\n",
    "# # Importane of variable\n",
    "# slope, intercept, r_value, _, _ = stats.linregress(np.log(pricesq), target.values)\n",
    "\n",
    "# # Plot\n",
    "# plt.subplots(figsize=(10, 5))\n",
    "# plt.plot(np.arange(len(sortDF)), round(sortDF['medianPricesq']))\n",
    "# plt.title('Price per ft^2')\n",
    "# plt.xlabel('Neighborhoods')\n",
    "# plt.ylabel('Ratio price per ft^2')\n",
    "# plt.xticks(np.arange(len(sortDF)), sortDF.iloc[:,0], rotation=70)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartile = train['SalePrice'].quantile([.25, .75, 0.95])\n",
    "quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bins as quartile\n",
    "bins = quartile.tolist()\n",
    "bins.insert(0, 0)\n",
    "bins.append(train['SalePrice'].max() + 1)\n",
    "\n",
    "'''Labels are organized as following:\n",
    "L  : low price\n",
    "M  : medium price\n",
    "H  : high price\n",
    "EH : extreme high price'''\n",
    "labels = ['L','M','H','EH']\n",
    "\n",
    "# binning in categories\n",
    "train['bin'] = pd.cut(train['SalePrice'], bins=bins, labels=labels)\n",
    "train[['SalePrice','bin']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "var = train.drop(['SalePrice'], axis=1).select_dtypes(include=[np.number]).columns\n",
    "mx = pd.melt(train, id_vars=['SalePrice', 'bin'], value_vars=var)\n",
    "\n",
    "pt1 = sns.FacetGrid (mx, col='variable',\\\n",
    "                    hue='bin',\\\n",
    "                    palette='Set1',\\\n",
    "                    hue_order=['EH','H','M','L'],\\\n",
    "                    col_wrap=4, sharex=False, sharey=False)\n",
    "\n",
    "pt1 = (pt1.map(plt.scatter, 'value', 'SalePrice',\\\n",
    "          marker='v',\\\n",
    "          alpha=0.8).add_legend())\n",
    "pt1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(x,y,**kwargs):\n",
    "            sns.boxplot(x=x,y=y)\n",
    "            x = plt.xticks(rotation=90)\n",
    "\n",
    "cat = [f for f in train.columns if train.dtypes[f] == 'object']\n",
    "\n",
    "p = pd.melt(train, id_vars='SalePrice', value_vars=cat)\n",
    "pt2 = sns.FacetGrid (p, col='variable',\\\n",
    "                     col_wrap=3,\\\n",
    "                     sharex=False, sharey=False, size=5)\n",
    "\n",
    "pt2 = pt2.map(boxplot, 'value', 'SalePrice')\n",
    "pt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null values and inconsistencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there null values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check columns where there are null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkMissingData(inputDF):\n",
    "    # Checking the columns with missing data\n",
    "    nullData = inputDF.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (inputDF.isnull().sum()/inputDF.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([nullData, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "    # Selecting the columns with the missing data\n",
    "    missing_inputDF = missing_data.loc[missing_data['Total'] > 0]\n",
    "    print(missing_inputDF.count())\n",
    "    \n",
    "    return missing_inputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = checkMissingData(dataset)\n",
    "missing_list = list(missing.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check type variables which contain null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the types of the columns with missing data\n",
    "dataset[missing_list].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill PoolQC values with None\n",
    "dataset['PoolQC'] = dataset['PoolQC'].fillna(value='None')\n",
    "\n",
    "# Fill NaN MasVnrArea with 0\n",
    "dataset['MasVnrArea'] = dataset['MasVnrArea'].fillna(value=0)\n",
    "\n",
    "# Some values from Garage Year Built are missing. We will fill it\n",
    "# wiith the same year of construction\n",
    "dataset['GarageYrBlt'] = dataset['GarageYrBlt'].fillna(value=dataset['YearBuilt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the median Lot Frontage per Neighborhood\n",
    "lot_frontage_median = dataset[['Neighborhood', 'LotFrontage']]\\\n",
    "                    .groupby(['Neighborhood'])\\\n",
    "                    .agg(['median'])\\\n",
    "                    .reset_index()\n",
    "# Creating a dictionary from the Lot Frontage per Neighborhood\n",
    "lot_dict = lot_frontage_median.set_index('Neighborhood').to_dict()\n",
    "# Replacing NaN values using the dictionary\n",
    "lot_frontage_clean = dataset.LotFrontage.fillna(dataset.Neighborhood.map(lot_dict[('LotFrontage', \\\n",
    "                                                                             'median')]))\n",
    "# Replacing the Lot Frontage column with the cleaned column\n",
    "dataset['LotFrontage'] = lot_frontage_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting missing values by dtype\n",
    "data_object = dataset[missing_list].select_dtypes(include='object')\n",
    "object_list = list(data_object)\n",
    "data_float = dataset[missing_list].select_dtypes(include='float')\n",
    "float_list = list(data_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace values from columns with object type\n",
    "def replaceObjectData(inputDF, missing_list):\n",
    "    for col in missing_list:\n",
    "        # NaN values replaced with 'None'\n",
    "        clean_data = inputDF[col].fillna(value = 'None')\n",
    "        inputDF[col] = clean_data\n",
    "    return inputDF\n",
    "\n",
    "data_object = replaceObjectData(data_object, object_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace values from columns with float type\n",
    "def replaceFloatDafig(inputDF, missing_list):\n",
    "    for col in missing_list:\n",
    "        # NaN values replaced with the mean of the column to avoid skewed data\n",
    "        clean_data = inputDF[col].fillna(value = 0)\n",
    "        inputDF[col] = clean_data\n",
    "    return inputDF\n",
    "\n",
    "data_float = replaceObjectData(data_float, float_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values from original dataframe with corrected ones\n",
    "dataset[object_list] = data_object\n",
    "dataset[float_list] = data_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([dataset[:1200], train['bin']], axis=1)\n",
    "test = dataset[-260:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Parameters to play by user\n",
    "   --------------------------'''\n",
    "cat = 'LotArea'\n",
    "contamination = 0.003\n",
    "\n",
    "# fit the model\n",
    "clf = IsolationForest(contamination=contamination, random_state=np.random.RandomState(1234))\n",
    "clf.fit(train[cat].values.reshape(-1,1))\n",
    "y_pred = clf.predict(train[cat].values.reshape(-1,1))\n",
    "\n",
    "# Index outliers\n",
    "idx = np.where(y_pred < 0)\n",
    "\n",
    "# Plot data and outliers\n",
    "sns.pairplot(x_vars=[cat],\\\n",
    "             y_vars=['SalePrice'],\\\n",
    "             data=train,\\\n",
    "             hue='bin', size=6)\n",
    "plt.scatter(train[cat].iloc[idx],\\\n",
    "            train['SalePrice'].iloc[idx],\\\n",
    "            marker='x', s=300, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of variable and contamination\n",
    "catOutliers = [('LotFrontage', 0.005),\\\n",
    "               ('MasVnrArea', 0.005),\\\n",
    "               ('BsmtFinSF1', 0.0005),\\\n",
    "               ('BsmtFinSF2', 0.0005),\\\n",
    "               ('BsmtUnfSF', 0.0005),\\\n",
    "               ('TotalBsmtSF', 0.003),\\\n",
    "               ('1stFlrSF', 0.0015),\\\n",
    "               ('2ndFlrSF', 0.0015),\\\n",
    "               ('GrLivArea', 0.002),\\\n",
    "               ('GarageArea', 0.002),\\\n",
    "               ('WoodDeckSF', 0.002),\\\n",
    "               ('OpenPorchSF', 0.002),\\\n",
    "               ('EnclosedPorch', 0.0005),\\\n",
    "               ('MiscVal', 0.0005)\n",
    "              ]\n",
    "\n",
    "# # Definition of variable and contamination\n",
    "# catOutliers = [('LotFrontage', 0.005),\\\n",
    "#                ('LotArea', 0.003),\\\n",
    "#                ('MasVnrArea', 0.005),\\\n",
    "#                ('BsmtFinSF1', 0.0005),\\\n",
    "#                ('BsmtFinSF2', 0.0005),\\\n",
    "#                ('BsmtUnfSF', 0.0005),\\\n",
    "#                ('TotalBsmtSF', 0.003),\\\n",
    "#                ('1stFlrSF', 0.0015),\\\n",
    "#                ('2ndFlrSF', 0.0015),\\\n",
    "#                ('GrLivArea', 0.002),\\\n",
    "#                ('GarageArea', 0.002),\\\n",
    "#                ('WoodDeckSF', 0.002),\\\n",
    "#                ('OpenPorchSF', 0.002),\\\n",
    "#                ('EnclosedPorch', 0.0005),\\\n",
    "#                ('MiscVal', 0.0005)\n",
    "#               ]\n",
    "\n",
    "idx = np.empty(())\n",
    "for var, contam in catOutliers:\n",
    "    \n",
    "    # fit the model\n",
    "    clf = IsolationForest(contamination=contam, random_state=np.random.RandomState(1234))\n",
    "    clf.fit(train[var].values.reshape(-1,1))\n",
    "    outliers = clf.predict(train[var].values.reshape(-1,1))\n",
    "\n",
    "    # Index outliers\n",
    "    idx = np.where(outliers < 0)\n",
    "    \n",
    "    # Drop all rows wihich match with idx\n",
    "    train = train.drop(train.index[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some aditional outliers deletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(\\\n",
    "             ((train['SalePrice'] > 350000) & (train['OverallCond'] < 2.5)) |\\\n",
    "             ((train['SalePrice'] > 600000) & (np.logical_and(train['OverallCond']>5, train['OverallCond']<7.5)))\\\n",
    "            )\n",
    "train = train.drop(train.index[idx[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total number of bathrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agragate all bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_bathrooms(inputDF, plot=False):\n",
    "    \n",
    "    # Select all column that contain bath in house\n",
    "    BathVar = ['FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath']\n",
    "    totalBath = inputDF.loc[:, BathVar]\n",
    "    \n",
    "    # agregatate all column\n",
    "    totalBath = totalBath.sum(axis=1)\n",
    "    \n",
    "    # Binning total bath greater than 4\n",
    "    totalBath_bins = totalBath.where(totalBath <= 4, 4)\n",
    "    \n",
    "    if plot is True:\n",
    "        pd1 = pd.concat([totalBath.rename('x'),\n",
    "                        inputDF['SalePrice'].rename('y'),\n",
    "                        inputDF['bin'].rename('name')], axis=1)\n",
    "#         fig = plt.figure(figsize=(14,4))\n",
    "#         plt.subplot(1,2,1)\n",
    "        for x, y, name in pd1.iterrows():\n",
    "            print (pd1.x, pd1.y, pd1.name)\n",
    "#             plt.plot(x, y, 'o', label=name)\n",
    "#         plt.subplot(1,2,2)\n",
    "#         plt.plot(totalBath_bins, inputDF['SalePrice'], '.')\n",
    "        \n",
    "#     # Concatenate with inputDF\n",
    "#     inputDF = pd.concat([inputDF, totalBath_bins.rename('TotalBath_bins')], axis=1)\n",
    "    \n",
    "#     # Convert to numeric\n",
    "#     inputDF['TotalBath_bins'] = inputDF['TotalBath_bins'].astype('int64')\n",
    "\n",
    "#     # Drop all bathrooms variables\n",
    "#     inputDF = inputDF.drop(columns = BathVar)\n",
    "    \n",
    "    return pd1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combine_bathrooms(train, plot=True)\n",
    "# test = combine_bathrooms(test, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age of building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_age(inputDF, plot=False):\n",
    "    \n",
    "    # Age og house\n",
    "    age = inputDF['YrSold'] - inputDF['YearRemodAdd']\n",
    "    \n",
    "    if plot is True:\n",
    "        plt.figure(figsize=(7,4))\n",
    "        plt.plot(age, inputDF['SalePrice'], '.')\n",
    "        \n",
    "    # Concatenate with inputDF\n",
    "    inputDF = pd.concat([inputDF, age.rename('BuildAge')], axis=1)\n",
    "\n",
    "    # Drop all bathrooms variables\n",
    "    inputDF = inputDF.drop(columns = ['YrSold', 'YearRemodAdd'])\n",
    "    \n",
    "    return inputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_age(train, plot=True)\n",
    "test = create_age(test, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregate all first and second floor area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_floors(inputDF, plot=False):\n",
    "    \n",
    "    AreaVar = ['1stFlrSF', '2ndFlrSF', 'TotalBsmtSF']\n",
    "    totalLivingArea = inputDF[AreaVar[0]] + inputDF[AreaVar[1]] + inputDF[AreaVar[2]]\n",
    "    \n",
    "    if plot is True:\n",
    "        plt.figure(figsize=(7,4))\n",
    "        plt.plot(totalLivingArea, inputDF['SalePrice'], '.')\n",
    "        \n",
    "    # Concatenate with inputDF\n",
    "    inputDF = pd.concat([inputDF, totalLivingArea.rename('TotLivingArea')], axis=1)\n",
    "\n",
    "    # Drop all bathrooms variables\n",
    "    inputDF = inputDF.drop(columns = AreaVar)\n",
    "    \n",
    "    return inputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = agg_floors(train, plot=True)\n",
    "test = agg_floors(test, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agregate all porch variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_porch(inputDF, plot=False):\n",
    "    \n",
    "    porchVar = ['EnclosedPorch','3SsnPorch','ScreenPorch']\n",
    "    porch = np.sum(inputDF[porchVar], axis=1)\n",
    "    \n",
    "    if plot is True:\n",
    "        plt.plot(porch, inputDF['SalePrice'], '.')\n",
    "\n",
    "    # Concatenate with inputDF\n",
    "    inputDF = pd.concat([inputDF, porch.rename('Porch')], axis=1)\n",
    "\n",
    "    # Drop all bathrooms variables\n",
    "    inputDF = inputDF.drop(columns = porchVar)\n",
    "    \n",
    "    return inputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = agg_porch(train, plot=True)\n",
    "test = agg_porch(test, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop some variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep GarageCars, GarageArea, GarageType, GarageQual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_car_var(inputDF):\n",
    "    \n",
    "    cars = ['GarageFinish', 'GarageQual', 'GarageCond']\n",
    "\n",
    "    # Drop all bathrooms variables\n",
    "    inputDF = inputDF.drop(columns = cars)\n",
    "    \n",
    "    return inputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = drop_car_var(train)\n",
    "test = drop_car_var(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_categorical_data(cateVar, target='SalePrice', col_wrap=4, size=4, rotat_label=False):\n",
    "    \n",
    "    '''Personalized bar plot (adding text)'''\n",
    "    def make_bar(dataX, dataY, counts, **kwargs):\n",
    "        \n",
    "        pal = sns.color_palette('RdYlBu', len(dataX))\n",
    "        g = sns.barplot(x=dataX,y=dataY, palette=np.array(pal[::-1]))\n",
    "        \n",
    "        if rotat_label is True:\n",
    "            dataX = plt.xticks(rotation=45)\n",
    "            \n",
    "        # Add text\n",
    "        x = g.patches\n",
    "        for x, y in zip(x, counts):\n",
    "            g.text(0.5*x.get_width()+x.get_x(), x.get_height(), y, ha='center')\n",
    "    \n",
    "    '''For each categorical feature the median \n",
    "    and how many samples per inner categories are computed'''\n",
    "    mergeCateDF = pd.DataFrame()\n",
    "    for cate_name in cateVar:\n",
    "        tempDF = train[[cate_name, target]].groupby([cate_name]).agg(['count'])\n",
    "        \n",
    "#     a = tempDF.groupby(['bin']).agg(['count'])\n",
    "    print (tempDF)\n",
    "    \n",
    "        \n",
    "#         # Group each category to agg by median SalePrice value and count\n",
    "#         tempDF = train[[cate_name, target]]\\\n",
    "#                     .groupby([cate_name])\\\n",
    "#                     .agg(['median', 'count'])\\\n",
    "#                     .reset_index() \n",
    "                    \n",
    "#         # Delete one level index\n",
    "#         tempDF.columns = tempDF.columns.droplevel()\n",
    "        \n",
    "#         # Rename all columns\n",
    "#         tempDF.columns = ['cate', target, 'counts']\n",
    "        \n",
    "#         # Insert category name\n",
    "#         tempDF.insert(loc=0, column='name', value=cate_name)\n",
    "        \n",
    "#         # Merge all categories\n",
    "#         mergeCateDF = mergeCateDF.append([tempDF])\n",
    "\n",
    "#     # Plot           \n",
    "#     pltCate = sns.FacetGrid (mergeCateDF, col='name', palette='Set1',\\\n",
    "#                              col_wrap=col_wrap, sharex=False, sharey=False, size=size)\n",
    "\n",
    "#     return pltCate.map(make_bar,'cate',target,'counts') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve all categorical columns\n",
    "# categoCol = train.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# cate2Var = ['MSSubClass','MSZoning','Exterior1st','Exterior2nd','Neighborhood']\n",
    "# cate1Var = [x for x in list(categoCol) if x not in cate2Var]\n",
    "\n",
    "\n",
    "# # Plot first group of categorical data\n",
    "# plot_categorical_data(cate1Var, target='SalePrice', col_wrap=4, size=3, rotat_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot second group cateogical data\n",
    "# plot_categorical_data(cate2Var, target='SalePrice', col_wrap=2, size=5, rotat_label=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transf_categorical_data(inputDF):\n",
    "    \n",
    "    # Map definition for some categorical values to ordinal numbers\n",
    "    qualities = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "    \n",
    "    categories = ['PoolQC','FireplaceQu','BsmtQual',\\\n",
    "                 'BsmtCond','KitchenQual','HeatingQC',\\\n",
    "                 'ExterQual','ExterCond']\n",
    "    \n",
    "    # Loop to map categorical values which share same qualities \n",
    "    for categ in categories:\n",
    "        inputDF[categ] = inputDF[categ].map(qualities)\n",
    "\n",
    "    # Map categorical feautres independently and according to inputDF information\n",
    "    inputDF['LotShape'] = inputDF['LotShape'].map({'IR3':0, 'IR2':1, 'IR1':2, 'Reg':3})\n",
    "    inputDF['BsmtExposure'] = inputDF['BsmtExposure'].map({'None':0, 'No':1, 'Mn':2, 'Av':3, 'Gd':4})\n",
    "    inputDF['BsmtFinType1'] = inputDF['BsmtFinType1'].map({'None':0, 'Unf':1, 'LwQ':2,\\\n",
    "                                                     'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6})\n",
    "    inputDF['BsmtFinType2'] = inputDF['BsmtFinType2'].map({'None':0, 'Unf':1, 'LwQ':2,\\\n",
    "                                                     'Rec':3, 'BLQ':4, 'ALQ':5, 'GLQ':6})\n",
    "    inputDF['MasVnrType'] = inputDF['MasVnrType'].map({'None':0, 'BrkCmn':0, 'BrkFace':1, 'Stone':2})\n",
    "    inputDF['Functional'] = inputDF['Functional'].map({'Sal':0, 'Sev':1, 'Maj2':2, 'Maj1':3,\\\n",
    "                                                 'Mod':4, 'Min2':5, 'Min1':6, 'Typ':7})\n",
    "    inputDF['CentralAir'] = inputDF['CentralAir'].map({'N':0, 'Y':1})\n",
    "    inputDF['LandSlope'] = inputDF['LandSlope'].map({'Sev':0, 'Mod':1, 'Gtl':2})\n",
    "    inputDF['Street'] = inputDF['Street'].map({'Grvl':0, 'Pave':1})\n",
    "    inputDF['PavedDrive'] = inputDF['PavedDrive'].map({'N':0, 'P':1, 'Y':2})\n",
    "    \n",
    "    return inputDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = transf_categorical_data(train)\n",
    "test = transf_categorical_data(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsmtType1(inputDF):\n",
    "    \n",
    "    # Onehot encoding and then multiply by continous variable\n",
    "    joinBsmType1 = pd.get_dummies(inputDF['BsmtFinType1'], prefix='enc_BsmType1').multiply(inputDF['BsmtFinSF1'], axis=0)\n",
    "    joinBsmType1 = joinBsmType1.drop(joinBsmType1.columns[[0]], axis=1)\n",
    "#     print (joinBsmType1[:3])\n",
    "\n",
    "    # Concatenate with inputDF\n",
    "    inputDF = pd.concat([inputDF, joinBsmType1], axis=1)\n",
    "\n",
    "    # Drop columns\n",
    "    inputDF = inputDF.drop(columns = ['BsmtFinType1', 'BsmtFinSF1'])\n",
    "    \n",
    "    return inputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = bsmtType1(train)\n",
    "# test = bsmtType1(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsmtType2(inputDF):\n",
    "    \n",
    "    # Onehot encoding and then multiply by continous variable\n",
    "    joinBsmType2 = pd.get_dummies(inputDF['BsmtFinType2'], prefix='enc_BsmType2').multiply(inputDF['BsmtFinSF2'], axis=0)\n",
    "    joinBsmType2 = joinBsmType2.drop(joinBsmType2.columns[[0]], axis=1)\n",
    "#     print (joinBsmType2[:3])\n",
    "\n",
    "    # Concatenate with inputDF\n",
    "    inputDF = pd.concat([inputDF, joinBsmType2], axis=1)\n",
    "\n",
    "    # Drop columns\n",
    "    inputDF = inputDF.drop(columns = ['BsmtFinType2', 'BsmtFinSF2'])\n",
    "    \n",
    "    return inputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = bsmtType2(train)\n",
    "# test = bsmtType2(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood encoding\n",
    "\n",
    "for more details follow this __[link](https://www.kaggle.com/tnarik/likelihood-encoding-of-categorical-features)__ and the discussion here __[link](https://datascience.stackexchange.com/questions/11024/encoding-categorical-variables-using-likelihood-estimation)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot results\n",
    "# nd = pd.melt(dataset, value_vars=varTrans)\n",
    "# n1 = sns.FacetGrid(nd, col='variable', col_wrap=4, sharex=False, sharey=False)\n",
    "# n1.map(sns.distplot, 'value')\n",
    "# n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop all previous categorical data\n",
    "# dataset = dataset.drop(columns = cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Roof Material\n",
    "Group variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start one hot enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = train.select_dtypes(exclude=[np.number]).columns\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_rem = ['bin', 'SalePrice']\n",
    "cat_features = [x for x in list(cat_features) if x not in cate_rem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cateDF = pd.DataFrame()\n",
    "for i in cat_features:\n",
    "    dummyDF = pd.get_dummies(dataset[[i]], prefix=i, drop_first=True)\n",
    "    cateDF = pd.concat([cateDF, dummyDF], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHot_train = cateDF[:1200]\n",
    "oneHot_test = cateDF[-260:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHot_train = pd.DataFrame(oneHot_train, index=train.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all categorical data converted to numerical ones\n",
    "train = pd.concat([train, oneHot_train], axis=1)\n",
    "test = pd.concat([test, oneHot_test], axis=1)\n",
    "\n",
    "# Drop all previous categorical data\n",
    "train = train.drop(columns = cat_features)\n",
    "test = test.drop(columns = cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creation_categorical_feat(inputDF):\n",
    "    \n",
    "    # Feature 1\n",
    "    ft1 = inputDF['MSZoning_RL']*inputDF['Condition2_Norm']\n",
    "    # Feature 2\n",
    "    ft2 = inputDF['MSZoning_RL']*inputDF['Alley_None']\n",
    "    # Feature 3\n",
    "    ft3 = inputDF['MSZoning_RL']*inputDF['SaleType_WD']\n",
    "    # Feature 4\n",
    "    ft4 = inputDF['Alley_None']*inputDF['LandContour_Lvl']\n",
    "    # Feature 4\n",
    "    ft5 = inputDF['MSZoning_RL']*inputDF['LandContour_Lvl']\n",
    "    # Feature 4\n",
    "    ft6 = inputDF['MSZoning_RL']*inputDF['LotConfig_Inside']\n",
    "\n",
    "    # Concatenate all categorical data converted to numerical ones\n",
    "    inputDF = pd.concat([inputDF, ft1.rename('ft1'), ft2.rename('ft2'),\\\n",
    "                         ft3.rename('ft3'), ft4.rename('ft4'), ft5.rename('ft5'),\\\n",
    "                         ft6.rename('ft6')], axis=1)\n",
    "    \n",
    "    return inputDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = creation_categorical_feat(train)\n",
    "# test = creation_categorical_feat(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there are NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = checkMissingData(test)\n",
    "missing_list = list(missing.index)\n",
    "print (missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot results\n",
    "\n",
    "# nd = pd.melt(dataset, value_vars=varTrans)\n",
    "# n1 = sns.FacetGrid(nd, col='variable', col_wrap=4, sharex=False, sharey=False)\n",
    "# n1.map(sns.distplot, 'value')\n",
    "# n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.select_dtypes(exclude=[np.number]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SalePrice'] = train['SalePrice'].astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select train data and target\n",
    "X, y = train.drop(['SalePrice', 'bin'], axis=1), train['SalePrice']\n",
    "\n",
    "# Run classifier\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "features = clf.feature_importances_  \n",
    "\n",
    "# Concatenate with names\n",
    "feat_names = pd.DataFrame(data={'importance': features}, index=X.columns)\n",
    "feat_names = feat_names.sort_values(by='importance', ascending=False)\n",
    "# Thresold features\n",
    "thresold = 0.007\n",
    "Feat_names = feat_names[feat_names['importance'] > thresold]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.stem(np.arange(len(Feat_names)), Feat_names.values)\n",
    "plt.title('Features sorted by importance', fontsize=24)\n",
    "plt.xticks(np.arange(len(Feat_names)), Feat_names.index, rotation=85, fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feat_names.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select train data and target\n",
    "X, y = train.drop(['SalePrice', 'bin'], axis=1), train['SalePrice'].apply(np.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testStat, skew = test_stats_skewness(y)\n",
    "print ('The skewness is: {:.4f}'.format(skew))\n",
    "print ('The test statistics at 5% sign level of confidence is {:.3f}'.format(testStat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    shuffle=True,\n",
    "                                                    test_size=0.20, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lassoMd = Lasso(normalize=True, max_iter=1e5)\n",
    "param_grid = {'alpha': [0.00065, 0.0006, 0.00055, 0.00003, 0.00003, 0.000005]}\n",
    "\n",
    "gridLasso = GridSearchCV(lassoMd, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "gridLasso.fit(X, y)\n",
    "\n",
    "print (gridLasso.best_params_)\n",
    "print (gridLasso.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# 0.000065\n",
    "# 0.000001\n",
    "lasso = Lasso(alpha=0.0001, normalize=True, max_iter=1e5)\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred = lasso.predict(X_train)\n",
    "\n",
    "error = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "print ('Error: {:.6f}'.format(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "alphas = np.array([0.01,0.001, 0.005, 0.008, 0.0001])\n",
    "\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = ElasticNet(l1_ratio=.85, normalize=True, max_iter=1e6, random_state=3)\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(X_train, y_train)\n",
    "# print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENet = ElasticNet(alpha=0.0001, l1_ratio=.85, normalize=True, max_iter=1e6)\n",
    "ENet.fit(X_train, y_train)\n",
    "y_pred = ENet.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error = np.sqrt(mean_squared_error(y_pred, y_train))\n",
    "error "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunning Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DMatrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# \"Learn\" the mean from the training data\n",
    "mean_train = np.mean(y_train)\n",
    "\n",
    "# Get predictions on the test set\n",
    "baseline_predictions = np.ones(y_test.shape) * mean_train\n",
    "\n",
    "# Compute MAE\n",
    "mae_baseline = np.sqrt(mean_squared_error(y_test, baseline_predictions))\n",
    "\n",
    "print(\"Baseline RMSE is {:.4f}\".format(mae_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'max_depth':2,\n",
    "    'min_child_weight': 1,\n",
    "    'eta':.05,\n",
    "    'subsample': 1,\n",
    "    'gamma':0,\n",
    "    'colsample_bytree': 1,\n",
    "    # Other parameters\n",
    "    'objective':'reg:linear',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['eval_metric'] = 'rmse'\n",
    "num_boost_round = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = xgb.train(\n",
    "#     params,\n",
    "#     dtrain,\n",
    "#     num_boost_round=num_boost_round,\n",
    "#     evals=[(dtest, 'Test')],\n",
    "#     early_stopping_rounds=10\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best RMSE: {:.4f} with {} rounds\".format(\n",
    "#                  model.best_score,\n",
    "#                  model.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgb.cv(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=num_boost_round,\n",
    "    seed=42,\n",
    "    nfold=5,\n",
    "    metrics={'rmse'},\n",
    "    early_stopping_rounds=15\n",
    ")\n",
    "\n",
    "cv_results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_results['test-rmse-mean'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune max_depth and min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try wider intervals with a larger step between\n",
    "# each value and then narrow it down. Here after several\n",
    "# iteration I found that the optimal value was in the\n",
    "# following ranges.\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(2,10,2)\n",
    "    for min_child_weight in range(1,4,2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial best params and MAE\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "                             max_depth,\n",
    "                             min_child_weight))\n",
    "\n",
    "    # Update our parameters\n",
    "    params['max_depth'] = max_depth\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=77,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=15\n",
    "    )\n",
    "\n",
    "    # Update best RMSE\n",
    "    mean_mae = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].idxmin()\n",
    "    print(\"\\tRMSE {:.5f} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (max_depth,min_child_weight)\n",
    "\n",
    "print(\"Best params: {}, {}, RMSE: {:.5f}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = 2\n",
    "params['min_child_weight'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(6,10)]\n",
    "    for colsample in [i/10. for i in range(6,10)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "# We start by the largest values and go down to the smallest\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    print(\"CV with subsample={}, colsample={}\".format(\n",
    "                             subsample,\n",
    "                             colsample))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['subsample'] = subsample\n",
    "    params['colsample_bytree'] = colsample\n",
    "\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        seed=42,\n",
    "        nfold=5,\n",
    "        metrics={'rmse'},\n",
    "        early_stopping_rounds=15\n",
    "    )\n",
    "\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {:.5f} for {} rounds\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = (subsample,colsample)\n",
    "\n",
    "print(\"Best params: {}, {}, RMSE: {:.5f}\".format(best_params[0], best_params[1], min_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['subsample'] = 0.8\n",
    "params['colsample'] = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#This can take some time\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for gamma in [0,0.1,0.2,0.3,0.4,0.5]:\n",
    "    print(\"CV with eta={}\".format(gamma))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['gamma'] = gamma\n",
    "\n",
    "    # Run and time CV\n",
    "    cv_results = xgb.cv(\\\n",
    "            params,\\\n",
    "            dtrain,\\\n",
    "            num_boost_round=num_boost_round,\\\n",
    "            seed=42,\\\n",
    "            nfold=5,\\\n",
    "            metrics=['rmse'],\\\n",
    "            early_stopping_rounds=15)\n",
    "\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {:.5f} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "\n",
    "print(\"Best params: {}, RMSE: {:.5f}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "#This can take some time\n",
    "min_mae = float(\"Inf\")\n",
    "best_params = None\n",
    "\n",
    "for eta in [.3, .2, .1, .05, .01, .005, 0.00001]:\n",
    "    print(\"CV with eta={}\".format(eta))\n",
    "\n",
    "    # We update our parameters\n",
    "    params['eta'] = eta\n",
    "\n",
    "    # Run and time CV\n",
    "    cv_results = xgb.cv(\\\n",
    "            params,\\\n",
    "            dtrain,\\\n",
    "            num_boost_round=num_boost_round,\\\n",
    "            seed=42,\\\n",
    "            nfold=5,\\\n",
    "            metrics=['rmse'],\\\n",
    "            early_stopping_rounds=15)\n",
    "\n",
    "    # Update best score\n",
    "    mean_mae = cv_results['test-rmse-mean'].min()\n",
    "    boost_rounds = cv_results['test-rmse-mean'].argmin()\n",
    "    print(\"\\tRMSE {:.5f} for {} rounds\\n\".format(mean_mae, boost_rounds))\n",
    "    if mean_mae < min_mae:\n",
    "        min_mae = mean_mae\n",
    "        best_params = eta\n",
    "\n",
    "print(\"Best params: {}, RMSE: {:.5f}\".format(best_params, min_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = checkMissingData(test)\n",
    "missing_list = list(missing.index)\n",
    "print (missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(['SalePrice'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, \n",
    "                                                  y, \n",
    "                                                  shuffle=True,\n",
    "                                                  test_size=0.85, \n",
    "                                                  random_state=77)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Lasso model\n",
    "model_lasso = lasso\n",
    "model_Enet = ENet\n",
    "\n",
    "# Initializing XGBoost model\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.5, gamma=0, \n",
    "                             learning_rate=0.05, max_depth=2, \n",
    "                             min_child_weight=3.0, n_estimators=2200,\n",
    "                             subsample=0.8,\n",
    "                             random_state =42, nthread = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models\n",
    "model_lasso.fit(X_train, y_train)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "model_Enet.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "pred_lasso = model_lasso.predict(X_val)\n",
    "pred_xgb = model_xgb.predict(X_val)\n",
    "pred_Enet = model_Enet.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lasso_test = model_lasso.predict(X_test)\n",
    "pred_xgb_test = model_xgb.predict(X_test)\n",
    "pred_Enet_test = model_Enet.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_val = np.column_stack((pred_lasso, pred_Enet, pred_xgb))\n",
    "stacked_test = np.column_stack((pred_lasso_test, pred_Enet_test, pred_xgb_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying meta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying meta model -> Lasso regressor\n",
    "lasso_meta_model = model_Enet\n",
    "\n",
    "# Fit  model\n",
    "lasso_meta_model.fit(stacked_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final_test_data = lasso_meta_model.predict(stacked_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = 'Data/'\n",
    "filename = 'train_kaggle.csv'\n",
    "\n",
    "# Load training datset\n",
    "xx = pd.read_csv(filepath + filename)\n",
    "price = np.log(xx.SalePrice[-260:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er = np.sqrt(mean_squared_error(pred_final_test_data, price))\n",
    "er "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
